{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the following packages:\n",
    "\n",
    "```bash\n",
    "!pip install -q vertexai\n",
    "!pip install -q google-cloud-pipeline-components\n",
    "!pip install -q kfp\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.dsl import pipeline\n",
    "from kfp.dsl import component\n",
    "from kfp import compiler\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform import pipeline_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Environment Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "PROJECT_ID = config[\"PROJECT_ID\"]\n",
    "PIPELINE_ROOT = config[\"PIPELINE_ROOT\"]\n",
    "LOCATION = config[\"LOCATION\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing AI Platform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    staging_bucket=PIPELINE_ROOT,\n",
    "    location=LOCATION,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This connects to Vertex AI in Google Cloud.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Pipeline Components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component\n",
    "def add(a: int, b: int) -> int:\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get a warning about Python 3.7, you can ignore it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component()\n",
    "def multiply_2(a: int) -> int:\n",
    "    return a * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Components are the building blocks of Kubeflow Pipelines. Each component is a self-contained set of code that performs one step in the ML workflow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline\n",
    "def simple_pipeline(a: int = 1, b: int = 2):\n",
    "    add_task = add(a=a, b=b)\n",
    "    multiply_2_task = multiply_2(a=add_task.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline automatically creates a Kubeflow pipeline.\n",
    "\n",
    "The pipeline is DAG (Directed Acyclic Graph) of tasks. Each task is a component that performs one step in the pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=simple_pipeline, package_path=\"pipelines/simple_pipeline.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat pipelines/simple_pipeline.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This JSON file is the compiled pipeline.\n",
    "\n",
    "It is a serialized representation of the pipeline that can be run using the Kubeflow Pipelines API.\n",
    "\n",
    "> Note: The JSON file contain everything needed to run the pipeline, including the any secret values. Make sure to remove any sensitive information before sharing it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling Components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(multiply_2, \"components/multiply_2.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat components/multiply_2.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compile components individually as well. This is useful when you want to share components with others.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_job = pipeline_jobs.PipelineJob(\n",
    "    display_name=\"simple-pipeline\",\n",
    "    template_path=\"pipelines/simple_pipeline.json\",\n",
    "    parameter_values={\"a\": 43, \"b\": 24},\n",
    ")\n",
    "pipeline_job.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`job.run(sync=True)` will run the pipeline synchronously, meaning the cell will not finish executing until the pipeline is complete.\n",
    "\n",
    "If you want to run the pipeline asynchronously, you can use `job.run()`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Container Component\n",
    "\n",
    "by using the `@component` decorator, you can create a component from a Python function.\n",
    "Giving `base_image` argument to the decorator, you can specify the base image for the container.\n",
    "This makes it a python-containerized component.\n",
    "\n",
    "For example, the following code creates a Python container component from a Python function:\n",
    "\n",
    "```python\n",
    "@component(base_image='python:3.9')\n",
    "def my_component():\n",
    "    ...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scheduling Pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_job_schedule = aiplatform.PipelineJobSchedule(\n",
    "    pipeline_job=pipeline_job,\n",
    "    display_name=\"test_schedule\",\n",
    ")\n",
    "\n",
    "pipeline_job_schedule.create(\n",
    "    cron=\"0 * * * *\",  # Run every hour\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline API Documentation: https://google-cloud-pipeline-components.readthedocs.io/en/latest/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guides from Google:\n",
    "\n",
    "- https://cloud.google.com/vertex-ai/docs/pipelines/build-pipeline\n",
    "- https://codelabs.developers.google.com/vertex-pipelines-intro#0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Notebooks from Google: https://github.com/GoogleCloudPlatform/vertex-ai-samples/tree/main/notebooks/official/pipelines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Youtube Video Tutorial on Piplines:\n",
    "\n",
    "- https://www.youtube.com/watch?v=ayv0-rC8W1Q&\n",
    "- https://www.youtube.com/watch?v=ACkRqm7DSZQ\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
