{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "\n",
    "from kfp.dsl import pipeline\n",
    "from kfp.dsl import component\n",
    "from kfp.dsl import OutputPath\n",
    "\n",
    "from kfp import dsl\n",
    "\n",
    "from kfp.v2.dsl import (\n",
    "    Artifact,\n",
    "    Dataset,\n",
    "    Input,\n",
    "    Model,\n",
    "    Output,\n",
    "    Metrics,\n",
    "    component,\n",
    "    Markdown,\n",
    "    HTML,\n",
    ")\n",
    "\n",
    "from kfp import compiler\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "import json\n",
    "\n",
    "from rich import print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "PROJECT_ID = config[\"PROJECT_ID\"]\n",
    "PIPELINE_ROOT = config[\"PIPELINE_ROOT\"]\n",
    "LOCATION = config[\"LOCATION\"]\n",
    "SERVICE_ACCOUNT = config[\"SERVICE_ACCOUNT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authentication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    staging_bucket=PIPELINE_ROOT,\n",
    "    location=LOCATION,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\n",
    "        \"google-cloud-bigquery==3.15.0\",\n",
    "    ],\n",
    "    base_image=\"python:3.10.6\",\n",
    ")\n",
    "def run_mat_fact_model(credentials: dict):\n",
    "    from google.cloud import bigquery\n",
    "    import os\n",
    "    import json\n",
    "\n",
    "    credentials_info = json.loads(json.dumps(credentials))\n",
    "    with open(\"credentials.json\", \"w\") as f:\n",
    "        json.dump(credentials_info, f)\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"./credentials.json\"\n",
    "\n",
    "    client = bigquery.Client(location=\"EU\")\n",
    "\n",
    "    query = f\"\"\"\n",
    "    CREATE OR REPLACE MODEL `aicamp_2024.cf_model`\n",
    "        OPTIONS\n",
    "        (model_type='matrix_factorization',\n",
    "        feedback_type='implicit',\n",
    "        user_col='user_id',\n",
    "        item_col='item_id',\n",
    "        rating_col='rating',\n",
    "        l2_reg=30,\n",
    "        num_factors=15) AS\n",
    "        SELECT\n",
    "        user_id,\n",
    "        item_id,\n",
    "        LOG(view_duration) AS rating,\n",
    "        FROM `aicamp_2024.cf_view`\n",
    "    \"\"\"\n",
    "    client.query_and_wait(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "\n",
    "@component(\n",
    "    packages_to_install=[\n",
    "        \"pandas==2.2.2\",\n",
    "        \"google-cloud-bigquery==3.15.0\",\n",
    "        \"pyarrow==12.0.1\",\n",
    "        \"db-dtypes==1.1.1\",\n",
    "        \"tabulate\",\n",
    "    ],\n",
    "    base_image=\"python:3.10.6\",\n",
    ")\n",
    "def evaluate_model(\n",
    "    credentials: dict,\n",
    "    evaluation_metrics: Output[Markdown],\n",
    ") -> NamedTuple(\"Outputs\", [(\"deployment_decision\", str)]):\n",
    "    import pandas as pd\n",
    "    from google.cloud import bigquery\n",
    "    import os\n",
    "    import json\n",
    "\n",
    "    credentials_info = json.loads(json.dumps(credentials))\n",
    "    with open(\"credentials.json\", \"w\") as f:\n",
    "        json.dump(credentials_info, f)\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"./credentials.json\"\n",
    "\n",
    "    client = bigquery.Client(location=\"EU\")\n",
    "    query = f\"\"\"\n",
    "        SELECT\n",
    "            *\n",
    "        FROM\n",
    "            ML.EVALUATE(MODEL `aicamp_2024.cf_model`)\n",
    "    \"\"\"\n",
    "    df = client.query(query).to_dataframe()\n",
    "\n",
    "    with open(evaluation_metrics.path, \"w\") as f:\n",
    "        f.write(df.T.to_markdown())\n",
    "\n",
    "    if df[\"mean_average_precision\"].values[0] > 0.1:\n",
    "        deployment_decision = \"Deploy\"\n",
    "    else:\n",
    "        deployment_decision = \"Do not deploy\"\n",
    "    return (deployment_decision,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Table with Recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\n",
    "        \"pandas==2.2.2\",\n",
    "        \"google-cloud-bigquery==3.15.0\",\n",
    "        \"pyarrow==12.0.1\",\n",
    "        \"db-dtypes==1.1.1\",\n",
    "        \"tabulate\",\n",
    "    ],\n",
    "    base_image=\"python:3.10.6\",\n",
    ")\n",
    "def create_recommendation_table(\n",
    "    credentials: dict,\n",
    "    recommendation_table: Output[Dataset],\n",
    "    sample_output: Output[Markdown],\n",
    "):\n",
    "    from google.cloud import bigquery\n",
    "    import os\n",
    "    import json\n",
    "\n",
    "    credentials_info = json.loads(json.dumps(credentials))\n",
    "    with open(\"credentials.json\", \"w\") as f:\n",
    "        json.dump(credentials_info, f)\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"./credentials.json\"\n",
    "\n",
    "    client = bigquery.Client(location=\"EU\")\n",
    "\n",
    "    query = f\"\"\"\n",
    "    SELECT\n",
    "        user_id,\n",
    "        ARRAY_AGG(item_id\n",
    "            ORDER BY predicted_rating_confidence DESC LIMIT 5) AS recommended_items\n",
    "    FROM (\n",
    "        SELECT\n",
    "        *\n",
    "        FROM\n",
    "        ML.RECOMMEND(MODEL `aicamp_2024.cf_model`)\n",
    "        )\n",
    "    GROUP BY\n",
    "        user_id\n",
    "    \"\"\"\n",
    "    df = client.query(query).to_dataframe()\n",
    "\n",
    "    df.to_parquet(recommendation_table.path)\n",
    "\n",
    "    with open(sample_output.path, \"w\") as f:\n",
    "        f.write(df.sample(5).to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline(\n",
    "    name=\"collaborative_filtering_pipeline\",\n",
    "    pipeline_root=PIPELINE_ROOT + \"collaborative_filtering_pipeline\",\n",
    ")\n",
    "def collaborative_filtering_pipeline():\n",
    "    with open(\"service_account.json\", \"r\") as f:\n",
    "        raw_credential = json.load(f)\n",
    "\n",
    "    run_mat_fact_model_task = (\n",
    "        run_mat_fact_model(credentials=raw_credential)\n",
    "        .set_cpu_limit(\"1\")\n",
    "        .set_memory_limit(\"1G\")\n",
    "    )\n",
    "\n",
    "    evaluate_model_task = (\n",
    "        evaluate_model(credentials=raw_credential)\n",
    "        .set_cpu_limit(\"1\")\n",
    "        .set_memory_limit(\"1G\")\n",
    "        .after(run_mat_fact_model_task)\n",
    "    )\n",
    "\n",
    "    with dsl.If(\n",
    "        evaluate_model_task.outputs[\"deployment_decision\"] == \"Deploy\",\n",
    "        name=\"deploy_decision\",\n",
    "    ):\n",
    "        create_recommendation_table_task = (\n",
    "            create_recommendation_table(credentials=raw_credential)\n",
    "            .set_cpu_limit(\"1\")\n",
    "            .set_memory_limit(\"1G\")\n",
    "            .after(evaluate_model_task)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information about control flow, you can visit the following link:\n",
    "https://www.kubeflow.org/docs/components/pipelines/v2/pipelines/control-flow/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=collaborative_filtering_pipeline,\n",
    "    package_path=\"pipelines/collaborative_filtering_pipeline.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = aiplatform.PipelineJob(\n",
    "    display_name=\"collaborative_filtering_pipeline\",\n",
    "    template_path=\"pipelines/collaborative_filtering_pipeline.json\",\n",
    "    enable_caching=True,\n",
    ")\n",
    "job.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
